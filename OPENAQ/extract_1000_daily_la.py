"""
Extrai 1000 pontos de MÃ‰DIAS DIÃRIAS de NOâ‚‚ e Oâ‚ƒ de Los Angeles
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time


def extract_daily_measurements_from_sensor(
    api_key: str, sensor_id: int, parameter_name: str, target_points: int = 1000
) -> pd.DataFrame:
    """
    Extrai mÃ©dias diÃ¡rias de um sensor especÃ­fico

    Args:
        api_key: API key OpenAQ
        sensor_id: ID do sensor
        parameter_name: Nome do parÃ¢metro (no2, o3)
        target_points: NÃºmero alvo de pontos

    Returns:
        DataFrame com date e valor mÃ©dio diÃ¡rio
    """
    print(f"\nğŸ“Š Extraindo {parameter_name.upper()} DIÃRIO (Sensor {sensor_id})...")

    session = requests.Session()
    session.headers.update({"X-API-Key": api_key, "Accept": "application/json"})

    all_measurements = []
    page = 1

    # PerÃ­odo: Ãºltimos ~3 anos para ter 1000 dias
    end_date = datetime.utcnow()
    start_date = end_date - timedelta(days=1100)  # margem de seguranÃ§a

    try:
        while len(all_measurements) < target_points:
            params = {
                "datetime_from": start_date.isoformat() + "Z",
                "datetime_to": end_date.isoformat() + "Z",
                "limit": 1000,
                "page": page,
            }

            # Usar endpoint /days para mÃ©dias diÃ¡rias
            response = session.get(f"https://api.openaq.org/v3/sensors/{sensor_id}/days", params=params, timeout=30)
            response.raise_for_status()
            data = response.json()

            results = data.get("results", [])

            if not results:
                print(f"   Sem mais dados (pÃ¡gina {page})")
                break

            # Processar resultados
            for record in results:
                try:
                    # Timestamp estÃ¡ em period.datetimeFrom.utc
                    period = record.get("period", {})
                    datetime_from = period.get("datetimeFrom", {})
                    timestamp_str = datetime_from.get("utc")

                    if not timestamp_str:
                        continue

                    # Para mÃ©dias diÃ¡rias, usar apenas a data
                    timestamp = pd.to_datetime(timestamp_str).date()

                    # Valor Ã© a mÃ©dia diÃ¡ria
                    value = record.get("value")
                    unit = record.get("parameter", {}).get("units", "unknown")

                    if value is not None:
                        # Converter para Î¼g/mÂ³ se necessÃ¡rio
                        if unit.lower() == "ppm":
                            if parameter_name.lower() == "no2":
                                value = value * 1880  # NOâ‚‚: 1 ppm = 1880 Î¼g/mÂ³
                            elif parameter_name.lower() == "o3":
                                value = value * 1960  # Oâ‚ƒ: 1 ppm = 1960 Î¼g/mÂ³

                        all_measurements.append({"date": timestamp, "value": value})

                except Exception:
                    continue

            print(f"   PÃ¡gina {page}: +{len(results)} dias (total: {len(all_measurements)})")

            if len(all_measurements) >= target_points:
                break

            page += 1

            if page > 50:
                print(f"   âš ï¸  Limite de pÃ¡ginas atingido")
                break

            time.sleep(0.5)

        # Criar DataFrame
        df = pd.DataFrame(all_measurements)

        if len(df) > 0:
            df = df.sort_values("date").reset_index(drop=True)

            # Limitar ao nÃºmero alvo
            if len(df) > target_points:
                df = df.tail(target_points).reset_index(drop=True)

            print(f"   âœ… Total extraÃ­do: {len(df)} dias")
            print(f"   PerÃ­odo: {df['date'].min()} a {df['date'].max()}")
        else:
            print(f"   âš ï¸  Nenhum dado extraÃ­do")

        return df

    except Exception as e:
        print(f"   âŒ Erro: {e}")
        return pd.DataFrame(columns=["date", "value"])


def extract_1000_daily_points_los_angeles(api_key: str, output_csv: str = "la_air_quality_1000days.csv") -> str:
    """
    Extrai 1000 pontos de MÃ‰DIAS DIÃRIAS de NOâ‚‚ e Oâ‚ƒ de Los Angeles

    Args:
        api_key: API key OpenAQ
        output_csv: Caminho do CSV de saÃ­da

    Returns:
        Caminho do CSV gerado
    """
    print("=" * 80)
    print("ğŸŒ† EXTRAÃ‡ÃƒO DE 1000 MÃ‰DIAS DIÃRIAS - LOS ANGELES")
    print("=" * 80)
    print(f"\nğŸ¯ Objetivo: 1000 pontos de mÃ©dias diÃ¡rias para NOâ‚‚ e Oâ‚ƒ")
    print(f"ğŸ“ EstaÃ§Ã£o: Los Angeles - N. Main")

    # ========================================================================
    # SENSOR IDs (Los Angeles - N. Main)
    # ========================================================================

    NO2_SENSOR = 25192
    O3_SENSOR = 25193

    # ========================================================================
    # EXTRAIR DADOS DIÃRIOS
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("ğŸ“¥ EXTRAINDO MÃ‰DIAS DIÃRIAS")
    print("=" * 80)

    # NOâ‚‚
    df_no2 = extract_daily_measurements_from_sensor(
        api_key=api_key, sensor_id=NO2_SENSOR, parameter_name="no2", target_points=1000
    )
    df_no2 = df_no2.rename(columns={"value": "no2_ug_m3"})

    # Oâ‚ƒ
    df_o3 = extract_daily_measurements_from_sensor(
        api_key=api_key, sensor_id=O3_SENSOR, parameter_name="o3", target_points=1000
    )
    df_o3 = df_o3.rename(columns={"value": "o3_ug_m3"})

    # ========================================================================
    # COMBINAR DADOS
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("ğŸ”— COMBINANDO DADOS")
    print("=" * 80)

    # Criar uniÃ£o de todas as datas
    all_dates = set()

    if len(df_no2) > 0:
        all_dates.update(df_no2["date"].tolist())
    if len(df_o3) > 0:
        all_dates.update(df_o3["date"].tolist())

    # Criar DataFrame base
    df_combined = pd.DataFrame({"date": sorted(list(all_dates))})

    # Merge dados
    if len(df_no2) > 0:
        df_combined = df_combined.merge(df_no2, on="date", how="left")
    else:
        df_combined["no2_ug_m3"] = np.nan

    if len(df_o3) > 0:
        df_combined = df_combined.merge(df_o3, on="date", how="left")
    else:
        df_combined["o3_ug_m3"] = np.nan

    # Limitar a 1000 pontos (pegar os mais recentes)
    if len(df_combined) > 1000:
        df_combined = df_combined.tail(1000).reset_index(drop=True)

    print(f"\nğŸ“Š DADOS COMBINADOS:")
    print(f"   Total de dias: {len(df_combined)}")
    print(f"   NOâ‚‚: {df_combined['no2_ug_m3'].notna().sum()} dias")
    print(f"   Oâ‚ƒ: {df_combined['o3_ug_m3'].notna().sum()} dias")

    if len(df_combined) > 0:
        print(f"   PerÃ­odo: {df_combined['date'].min()} a {df_combined['date'].max()}")

        # Calcular duraÃ§Ã£o em anos
        duration_days = (df_combined["date"].max() - df_combined["date"].min()).days
        duration_years = duration_days / 365.25
        print(f"   DuraÃ§Ã£o: {duration_days} dias (~{duration_years:.1f} anos)")

    # ========================================================================
    # SALVAR CSV
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("ğŸ’¾ SALVANDO CSV")
    print("=" * 80)

    df_combined.to_csv(output_csv, index=False)

    print(f"\nâœ… CSV salvo: {output_csv}")
    print(f"   Linhas: {len(df_combined)}")
    print(f"   Colunas: date, no2_ug_m3, o3_ug_m3")

    # EstatÃ­sticas
    if df_combined["no2_ug_m3"].notna().any():
        print(f"\nğŸ“ˆ NOâ‚‚ (MÃ©dia DiÃ¡ria):")
        print(f"   MÃ©dia: {df_combined['no2_ug_m3'].mean():.2f} Î¼g/mÂ³")
        print(f"   MÃ­n: {df_combined['no2_ug_m3'].min():.2f} Î¼g/mÂ³")
        print(f"   MÃ¡x: {df_combined['no2_ug_m3'].max():.2f} Î¼g/mÂ³")
        print(f"   Desvio padrÃ£o: {df_combined['no2_ug_m3'].std():.2f} Î¼g/mÂ³")

    if df_combined["o3_ug_m3"].notna().any():
        print(f"\nğŸ“ˆ Oâ‚ƒ (MÃ©dia DiÃ¡ria):")
        print(f"   MÃ©dia: {df_combined['o3_ug_m3'].mean():.2f} Î¼g/mÂ³")
        print(f"   MÃ­n: {df_combined['o3_ug_m3'].min():.2f} Î¼g/mÂ³")
        print(f"   MÃ¡x: {df_combined['o3_ug_m3'].max():.2f} Î¼g/mÂ³")
        print(f"   Desvio padrÃ£o: {df_combined['o3_ug_m3'].std():.2f} Î¼g/mÂ³")

    print(f"\n{'=' * 80}")
    print("âœ… EXTRAÃ‡ÃƒO CONCLUÃDA!")
    print("=" * 80)

    return output_csv


if __name__ == "__main__":
    # Executar
    import os

    API_KEY = os.getenv("OPENAQ_API_KEY", "")

    if not API_KEY:
        print("âŒ OPENAQ_API_KEY nÃ£o configurada nas variÃ¡veis de ambiente")
        exit(1)

    csv_path = extract_1000_daily_points_los_angeles(api_key=API_KEY, output_csv="la_air_quality_1000days.csv")

    print(f"\nğŸ“ Arquivo gerado: {csv_path}")

    # Mostrar primeiras e Ãºltimas linhas
    print(f"\nğŸ“‹ PREVIEW:")
    df = pd.read_csv(csv_path)
    print("\nPrimeiros 5 dias:")
    print(df.head(5))
    print("\nÃšltimos 5 dias:")
    print(df.tail(5))
