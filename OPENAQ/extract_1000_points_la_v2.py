"""
Extrai 1000 pontos temporais (horas) de estaÃ§Ãµes em Los Angeles
Para NOâ‚‚, Oâ‚ƒ e HCHO
VersÃ£o 2: Usa sensor_ids diretos
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time


def extract_measurements_from_sensor(
    api_key: str, sensor_id: int, parameter_name: str, target_points: int = 10000
) -> pd.DataFrame:
    """
    Extrai mediÃ§Ãµes de um sensor especÃ­fico

    Args:
        api_key: API key OpenAQ
        sensor_id: ID do sensor
        parameter_name: Nome do parÃ¢metro (no2, o3, hcho)
        target_points: NÃºmero alvo de pontos

    Returns:
        DataFrame com timestamp e valor
    """
    print(f"\nğŸ“Š Extraindo {parameter_name.upper()} (Sensor {sensor_id})...")

    session = requests.Session()
    session.headers.update({"X-API-Key": api_key, "Accept": "application/json"})

    all_measurements = []
    page = 1

    # PerÃ­odo: Ãºltimos 2 anos
    end_date = datetime.utcnow()
    start_date = end_date - timedelta(days=730)

    try:
        while len(all_measurements) < target_points:
            params = {
                "datetime_from": start_date.isoformat() + "Z",
                "datetime_to": end_date.isoformat() + "Z",
                "limit": 10000,
                "page": page,
            }

            response = session.get(
                f"https://api.openaq.org/v3/sensors/{sensor_id}/measurements", params=params, timeout=30
            )
            response.raise_for_status()
            data = response.json()

            results = data.get("results", [])

            if not results:
                print(f"   Sem mais dados (pÃ¡gina {page})")
                break

            # Processar resultados
            for record in results:
                try:
                    # Timestamp estÃ¡ em period.datetimeFrom.utc
                    period = record.get("period", {})
                    datetime_from = period.get("datetimeFrom", {})
                    timestamp_str = datetime_from.get("utc")

                    if not timestamp_str:
                        continue

                    timestamp = pd.to_datetime(timestamp_str)
                    value = record.get("value")
                    unit = record.get("parameter", {}).get("units", "unknown")

                    if value is not None:
                        # Converter para Î¼g/mÂ³ se necessÃ¡rio
                        if unit.lower() == "ppm":
                            if parameter_name.lower() == "no2":
                                value = value * 1880
                            elif parameter_name.lower() == "o3":
                                value = value * 1960
                            elif parameter_name.lower() == "hcho":
                                value = value * 1230

                        all_measurements.append({"timestamp": timestamp, "value": value})

                except Exception:
                    continue

            print(f"   PÃ¡gina {page}: +{len(results)} mediÃ§Ãµes (total: {len(all_measurements)})")

            if len(all_measurements) >= target_points:
                break

            page += 1

            if page > 50:
                print(f"   âš ï¸  Limite de pÃ¡ginas atingido")
                break

            time.sleep(0.5)

        # Criar DataFrame
        df = pd.DataFrame(all_measurements)

        if len(df) > 0:
            df = df.sort_values("timestamp").reset_index(drop=True)

            # Limitar ao nÃºmero alvo
            if len(df) > target_points:
                df = df.tail(target_points).reset_index(drop=True)

            print(f"   âœ… Total extraÃ­do: {len(df)} pontos")
            print(f"   PerÃ­odo: {df['timestamp'].min()} a {df['timestamp'].max()}")
        else:
            print(f"   âš ï¸  Nenhum dado extraÃ­do")

        return df

    except Exception as e:
        print(f"   âŒ Erro: {e}")
        return pd.DataFrame(columns=["timestamp", "value"])


def extract_1000_points_los_angeles(api_key: str, output_csv: str = "la_air_quality_1000points.csv") -> str:
    """
    Extrai 1000 pontos temporais de estaÃ§Ãµes em Los Angeles

    EstaÃ§Ãµes usadas (do CSV de referÃªncia):
    - Los Angeles - N. Main: NOâ‚‚ (25192), Oâ‚ƒ (25193)
    - Pasadena: NOâ‚‚ (25473), Oâ‚ƒ (25474)
    - Long Beach: NOâ‚‚ (25188), Oâ‚ƒ (25189)

    Args:
        api_key: API key OpenAQ
        output_csv: Caminho do CSV de saÃ­da

    Returns:
        Caminho do CSV gerado
    """
    print("=" * 80)
    print("ğŸŒ† EXTRAÃ‡ÃƒO DE 1000 PONTOS - LOS ANGELES")
    print("=" * 80)
    print(f"\nğŸ¯ Objetivo: 1000 pontos para NOâ‚‚, Oâ‚ƒ e HCHO")
    print(f"ğŸ“ EstaÃ§Ãµes: Los Angeles, Pasadena, Long Beach")

    # ========================================================================
    # SENSOR IDs (do CSV de referÃªncia openaq_stations_usa.csv)
    # ========================================================================

    # Los Angeles - N. Main (34.066429, -118.226755)
    NO2_SENSOR = 25192
    O3_SENSOR = 25193

    # HCHO: NÃ£o hÃ¡ estaÃ§Ãµes com HCHO em Los Angeles (normal)
    HCHO_SENSOR = None

    # ========================================================================
    # EXTRAIR DADOS
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("ğŸ“¥ EXTRAINDO DADOS")
    print("=" * 80)

    # NOâ‚‚
    df_no2 = extract_measurements_from_sensor(
        api_key=api_key, sensor_id=NO2_SENSOR, parameter_name="no2", target_points=10000
    )
    df_no2 = df_no2.rename(columns={"value": "no2_ug_m3"})

    # Oâ‚ƒ
    df_o3 = extract_measurements_from_sensor(
        api_key=api_key, sensor_id=O3_SENSOR, parameter_name="o3", target_points=10000
    )
    df_o3 = df_o3.rename(columns={"value": "o3_ug_m3"})

    # HCHO
    if HCHO_SENSOR:
        df_hcho = extract_measurements_from_sensor(
            api_key=api_key, sensor_id=HCHO_SENSOR, parameter_name="hcho", target_points=1000
        )
        df_hcho = df_hcho.rename(columns={"value": "hcho_ug_m3"})
    else:
        print(f"\nâš ï¸  HCHO: Sem estaÃ§Ã£o disponÃ­vel em Los Angeles (normal - raro)")
        df_hcho = pd.DataFrame(columns=["timestamp", "hcho_ug_m3"])

    # ========================================================================
    # COMBINAR DADOS
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("ğŸ”— COMBINANDO DADOS")
    print("=" * 80)

    # Criar uniÃ£o de todos os timestamps
    all_timestamps = set()

    if len(df_no2) > 0:
        all_timestamps.update(df_no2["timestamp"].tolist())
    if len(df_o3) > 0:
        all_timestamps.update(df_o3["timestamp"].tolist())
    if len(df_hcho) > 0:
        all_timestamps.update(df_hcho["timestamp"].tolist())

    # Criar DataFrame base
    df_combined = pd.DataFrame({"timestamp": sorted(list(all_timestamps))})

    # Merge dados
    if len(df_no2) > 0:
        df_combined = df_combined.merge(df_no2, on="timestamp", how="left")
    else:
        df_combined["no2_ug_m3"] = np.nan

    if len(df_o3) > 0:
        df_combined = df_combined.merge(df_o3, on="timestamp", how="left")
    else:
        df_combined["o3_ug_m3"] = np.nan

    if len(df_hcho) > 0:
        df_combined = df_combined.merge(df_hcho, on="timestamp", how="left")
    else:
        df_combined["hcho_ug_m3"] = np.nan

    # Limitar a 10000 pontos (pegar os mais recentes)
    if len(df_combined) > 10000:
        df_combined = df_combined.tail(10000).reset_index(drop=True)

    print(f"\nğŸ“Š DADOS COMBINADOS:")
    print(f"   Total de pontos: {len(df_combined)}")
    print(f"   NOâ‚‚: {df_combined['no2_ug_m3'].notna().sum()} pontos")
    print(f"   Oâ‚ƒ: {df_combined['o3_ug_m3'].notna().sum()} pontos")
    print(f"   HCHO: {df_combined['hcho_ug_m3'].notna().sum()} pontos")

    if len(df_combined) > 0:
        print(f"   PerÃ­odo: {df_combined['timestamp'].min()} a {df_combined['timestamp'].max()}")

    # ========================================================================
    # SALVAR CSV
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("ğŸ’¾ SALVANDO CSV")
    print("=" * 80)

    df_combined.to_csv(output_csv, index=False)

    print(f"\nâœ… CSV salvo: {output_csv}")
    print(f"   Linhas: {len(df_combined)}")
    print(f"   Colunas: timestamp, no2_ug_m3, o3_ug_m3, hcho_ug_m3")

    # EstatÃ­sticas
    if df_combined["no2_ug_m3"].notna().any():
        print(f"\nğŸ“ˆ NOâ‚‚:")
        print(f"   MÃ©dia: {df_combined['no2_ug_m3'].mean():.2f} Î¼g/mÂ³")
        print(f"   MÃ­n: {df_combined['no2_ug_m3'].min():.2f} Î¼g/mÂ³")
        print(f"   MÃ¡x: {df_combined['no2_ug_m3'].max():.2f} Î¼g/mÂ³")

    if df_combined["o3_ug_m3"].notna().any():
        print(f"\nğŸ“ˆ Oâ‚ƒ:")
        print(f"   MÃ©dia: {df_combined['o3_ug_m3'].mean():.2f} Î¼g/mÂ³")
        print(f"   MÃ­n: {df_combined['o3_ug_m3'].min():.2f} Î¼g/mÂ³")
        print(f"   MÃ¡x: {df_combined['o3_ug_m3'].max():.2f} Î¼g/mÂ³")

    if df_combined["hcho_ug_m3"].notna().any():
        print(f"\nğŸ“ˆ HCHO:")
        print(f"   MÃ©dia: {df_combined['hcho_ug_m3'].mean():.2f} Î¼g/mÂ³")
        print(f"   MÃ­n: {df_combined['hcho_ug_m3'].min():.2f} Î¼g/mÂ³")
        print(f"   MÃ¡x: {df_combined['hcho_ug_m3'].max():.2f} Î¼g/mÂ³")

    print(f"\n{'=' * 80}")
    print("âœ… EXTRAÃ‡ÃƒO CONCLUÃDA!")
    print("=" * 80)

    return output_csv


if __name__ == "__main__":
    # Executar
    import os

    API_KEY = os.getenv("OPENAQ_API_KEY", "")

    if not API_KEY:
        print("âŒ OPENAQ_API_KEY nÃ£o configurada nas variÃ¡veis de ambiente")
        exit(1)

    csv_path = extract_1000_points_los_angeles(api_key=API_KEY, output_csv="la_air_quality_1000points.csv")

    print(f"\nğŸ“ Arquivo gerado: {csv_path}")

    # Mostrar primeiras linhas
    print(f"\nğŸ“‹ PREVIEW:")
    df = pd.read_csv(csv_path)
    print(df.head(10))
