{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Utilidades\n",
    "# -------------------------------------------\n",
    "def load_hourly_ws(csv_path_or_str):\n",
    "    \"\"\"\n",
    "    Lê CSV com colunas: timestamp(YYYYMMDDHH), ws2m.\n",
    "    Retorna DataFrame com índice datetime e frequência horária contínua.\n",
    "    \"\"\"\n",
    "    if isinstance(csv_path_or_str, str) and \"\\n\" in csv_path_or_str:\n",
    "        import io\n",
    "        df = pd.read_csv(io.StringIO(csv_path_or_str))\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path_or_str)\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"].astype(str), format=\"%Y%m%d%H\")\n",
    "    df = df.set_index(\"timestamp\").sort_index()\n",
    "\n",
    "    if df.index.tz is not None:\n",
    "        df.index = df.index.tz_localize(None)\n",
    "\n",
    "    # Grade horária contínua + preenchimento (se houver buracos)\n",
    "    full_range = pd.date_range(df.index.min(), df.index.max(), freq=\"H\")\n",
    "    df = df.reindex(full_range)\n",
    "    df.rename_axis(\"timestamp\", inplace=True)\n",
    "    df[\"ws2m\"] = df[\"ws2m\"].interpolate(method=\"time\").ffill().bfill()\n",
    "\n",
    "    return df[[\"ws2m\"]].astype(float)\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(((y_true - y_pred) ** 2).mean()))\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Random Forest: criação de features\n",
    "# -------------------------------------------\n",
    "def make_supervised(y_ser, lags_short=24, weekly_lags=(168, 167, 169), roll_windows=(3, 6, 12, 24)):\n",
    "    \"\"\"\n",
    "    Constrói X,y (um passo à frente) com:\n",
    "      - lags 1..24\n",
    "      - lags semanais (se existirem dados suficientes)\n",
    "      - médias e desvios móveis (3,6,12,24)\n",
    "      - sen/cos da hora do dia e dia da semana\n",
    "    \"\"\"\n",
    "    weekly_lags = tuple(L for L in weekly_lags if L < len(y_ser))\n",
    "    start = max([lags_short] + list(weekly_lags) + list(roll_windows)) + 1\n",
    "    if start >= len(y_ser):\n",
    "        return None, None\n",
    "\n",
    "    rows, ys = [], []\n",
    "    for t in range(start, len(y_ser)):\n",
    "        feats = {f\"lag_{L}\": y_ser.iloc[t - L] for L in range(1, lags_short + 1)}\n",
    "        for L in weekly_lags:\n",
    "            feats[f\"lag_{L}\"] = y_ser.iloc[t - L]\n",
    "        for w in roll_windows:\n",
    "            w_eff = min(w, t)\n",
    "            feats[f\"roll_mean_{w}\"] = y_ser.iloc[t - w_eff:t].mean()\n",
    "            feats[f\"roll_std_{w}\"] = y_ser.iloc[t - w_eff:t].std(ddof=0)\n",
    "\n",
    "        ts = y_ser.index[t]\n",
    "        feats[\"sin_h\"] = np.sin(2 * np.pi * ts.hour / 24)\n",
    "        feats[\"cos_h\"] = np.cos(2 * np.pi * ts.hour / 24)\n",
    "        feats[\"sin_w\"] = np.sin(2 * np.pi * ts.dayofweek / 7)\n",
    "        feats[\"cos_w\"] = np.cos(2 * np.pi * ts.dayofweek / 7)\n",
    "\n",
    "        rows.append(pd.Series(feats, name=ts))\n",
    "        ys.append(y_ser.iloc[t])\n",
    "\n",
    "    X = pd.DataFrame(rows)\n",
    "    y = pd.Series(ys, index=X.index, name=\"y\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def rf_predict_next_k(y_hist: pd.Series, k=24, X_cols=None, rf_pipe=None,\n",
    "                      lags_short=24, weekly_lags=(168, 167, 169), roll_windows=(3, 6, 12, 24)):\n",
    "    \"\"\"Previsão iterativa k passos à frente com Random Forest treinada.\"\"\"\n",
    "    weekly_lags = tuple(L for L in weekly_lags if L < len(y_hist))\n",
    "    y_work = y_hist.copy()\n",
    "    preds = []\n",
    "    last_ts = y_hist.index[-1]\n",
    "\n",
    "    for i in range(1, k + 1):\n",
    "        ts_i = last_ts + pd.Timedelta(hours=i)\n",
    "        feats = {f\"lag_{L}\": y_work.iloc[-L] for L in range(1, lags_short + 1)}\n",
    "        for L in weekly_lags:\n",
    "            feats[f\"lag_{L}\"] = y_work.iloc[-L]\n",
    "        for w in roll_windows:\n",
    "            w_eff = min(w, len(y_work))\n",
    "            feats[f\"roll_mean_{w}\"] = y_work.iloc[-w_eff:].mean()\n",
    "            feats[f\"roll_std_{w}\"] = y_work.iloc[-w_eff:].std(ddof=0)\n",
    "\n",
    "        # calendário\n",
    "        feats[\"sin_h\"] = np.sin(2 * np.pi * ts_i.hour / 24)\n",
    "        feats[\"cos_h\"] = np.cos(2 * np.pi * ts_i.hour / 24)\n",
    "        feats[\"sin_w\"] = np.sin(2 * np.pi * ts_i.dayofweek / 7)\n",
    "        feats[\"cos_w\"] = np.cos(2 * np.pi * ts_i.dayofweek / 7)\n",
    "\n",
    "        Xi = pd.DataFrame([feats], index=[ts_i])\n",
    "        if X_cols is not None:\n",
    "            Xi = Xi.reindex(columns=X_cols, fill_value=0.0)\n",
    "\n",
    "        y_hat = float(rf_pipe.predict(Xi)[0])\n",
    "        preds.append(y_hat)\n",
    "        y_work = pd.concat([y_work, pd.Series([y_hat], index=[ts_i])])\n",
    "\n",
    "    return pd.Series(preds, index=pd.date_range(last_ts + pd.Timedelta(hours=1), periods=k, freq=\"H\"))\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Treinar, validar, prever 24\n",
    "# -------------------------------------------\n",
    "def test_three_models_next24(csv_path=\"ws_hours.csv\"):\n",
    "    df = load_hourly_ws(csv_path)\n",
    "    y = df[\"ws2m\"].astype(float)\n",
    "\n",
    "    # janela de validação (último trecho)\n",
    "    val_len = max(24, min(168, int(len(y) * 0.25)))  # 25% (mín 24, máx 168)\n",
    "    if val_len >= len(y):\n",
    "        val_len = max(24, len(y) // 3)\n",
    "\n",
    "    y_train = y.iloc[:-val_len]\n",
    "    y_val = y.iloc[-val_len:]\n",
    "    future_idx = pd.date_range(y.index[-1] + pd.Timedelta(hours=1), periods=24, freq=\"H\")\n",
    "\n",
    "    results = {}\n",
    "    forecasts_24 = {}\n",
    "\n",
    "    # ---------- Modelo 1: SARIMA(1,0,1)(1,1,1,24) ----------\n",
    "    try:\n",
    "        sarima = SARIMAX(\n",
    "            y_train, order=(1, 0, 1), seasonal_order=(1, 1, 1, 24),\n",
    "            enforce_stationarity=False, enforce_invertibility=False\n",
    "        ).fit(disp=False)\n",
    "        sarima_val = sarima.forecast(steps=val_len)\n",
    "        results[\"SARIMA\"] = rmse(y_val, sarima_val)\n",
    "\n",
    "        sarima_full = SARIMAX(\n",
    "            y, order=(1, 0, 1), seasonal_order=(1, 1, 1, 24),\n",
    "            enforce_stationarity=False, enforce_invertibility=False\n",
    "        ).fit(disp=False)\n",
    "        forecasts_24[\"SARIMA\"] = pd.Series(sarima_full.forecast(steps=24), index=future_idx)\n",
    "    except Exception as e:\n",
    "        results[\"SARIMA\"] = np.inf\n",
    "        forecasts_24[\"SARIMA\"] = None\n",
    "\n",
    "    # ---------- Modelo 2: Holt-Winters (add, add, 24) ----------\n",
    "    try:\n",
    "        hw = ExponentialSmoothing(y_train, trend=\"add\", seasonal=\"add\", seasonal_periods=24).fit()\n",
    "        hw_val = hw.forecast(val_len)\n",
    "        results[\"HoltWinters\"] = rmse(y_val, hw_val)\n",
    "\n",
    "        hw_full = ExponentialSmoothing(y, trend=\"add\", seasonal=\"add\", seasonal_periods=24).fit()\n",
    "        forecasts_24[\"HoltWinters\"] = pd.Series(hw_full.forecast(24), index=future_idx)\n",
    "    except Exception as e:\n",
    "        results[\"HoltWinters\"] = np.inf\n",
    "        forecasts_24[\"HoltWinters\"] = None\n",
    "\n",
    "    # ---------- Modelo 3: Random Forest ----------\n",
    "    rf_rmse = np.inf\n",
    "    rf_fc = None\n",
    "    X_full, y_full = make_supervised(y)\n",
    "    if X_full is not None:\n",
    "        split_time = y.index[-val_len]\n",
    "        X_tr = X_full.loc[X_full.index < split_time]\n",
    "        y_tr = y_full.loc[X_full.index < split_time]\n",
    "        X_va = X_full.loc[X_full.index >= split_time]\n",
    "        y_va = y_full.loc[X_full.index >= split_time]\n",
    "\n",
    "        if len(X_tr) > 0 and len(X_va) > 0:\n",
    "            rf_pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler(with_mean=False)),\n",
    "                (\"rf\", RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1))\n",
    "            ])\n",
    "            rf_pipe.fit(X_tr, y_tr)\n",
    "            rf_val_pred = rf_pipe.predict(X_va)\n",
    "            rf_rmse = rmse(y_va, rf_val_pred)\n",
    "\n",
    "            # Refit full e previsão 24\n",
    "            rf_pipe.fit(X_full, y_full)\n",
    "            rf_fc = rf_predict_next_k(\n",
    "                y_hist=y, k=24, X_cols=X_full.columns, rf_pipe=rf_pipe\n",
    "            )\n",
    "\n",
    "    results[\"RandomForest\"] = rf_rmse\n",
    "    forecasts_24[\"RandomForest\"] = rf_fc\n",
    "\n",
    "    # ---------- Consolidação ----------\n",
    "    # imprime comparação de RMSE (validação)\n",
    "    print(\"RMSE validação (menor é melhor):\")\n",
    "    for m, s in results.items():\n",
    "        print(f\"  {m:<13s}: {s:.4f}\")\n",
    "\n",
    "    # previsões para os próximos 24 pontos (cada modelo)\n",
    "    print(\"\\nPrevisões (próximas 24h):\")\n",
    "    for m, fc in forecasts_24.items():\n",
    "        if fc is None:\n",
    "            print(f\"  {m:<13s}: [sem previsão]\")\n",
    "        else:\n",
    "            print(f\"  {m:<13s}: \" + \",\".join(f\"{v:.2f}\" for v in fc.values))\n",
    "\n",
    "    # modelo vencedor (pelo RMSE)\n",
    "    valid_items = [(m, s) for m, s in results.items() if np.isfinite(s) and forecasts_24[m] is not None]\n",
    "    if valid_items:\n",
    "        best_model = min(valid_items, key=lambda x: x[1])[0]\n",
    "        print(f\"\\nMelhor modelo (validação): {best_model}\")\n",
    "        print(\"Previsão final (24h do melhor): \" + \",\".join(f\"{v:.2f}\" for v in forecasts_24[best_model].values))\n",
    "    else:\n",
    "        print(\"\\nNenhum modelo pôde ser avaliado com sucesso.\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Execução\n",
    "# -------------------------------------------\n",
    "# Ajuste o caminho/arquivo se necessário:\n",
    "# Ex.: csv_path = \"ws_hours.csv\"\n",
    "csv_path = \"ws_hours.csv\"\n",
    "test_three_models_next24(csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
